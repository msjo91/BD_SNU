{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maryland Car Accident Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "Data file 'maryland_accident_dataset_by_report_no.csv' has already been trimmed.\n",
    "1. A single individual record is registered for each report case.\n",
    "2. Records including NaN are deleted.\n",
    "3. All individual registered are drivers. (PERSON_TYPE == 'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "Differentiate car accident cases.  \n",
    "Understand causes of casuality.  \n",
    "Design solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "Preprocessing  \n",
    "Clustering  \n",
    "Classifying    \n",
    "Insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29593"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data as DataFrame\n",
    "df = pd.read_csv('maryland_accident_dataset_by_report_no.csv')\n",
    "# df = pd.read_csv('maryland_1year_nan_contained.csv', low_memory=False)\n",
    "# Check total records\n",
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make all columns shown, find out the number of columns\n",
    "n = len(df.columns)\n",
    "# Change display setting\n",
    "pd.options.display.max_columns = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy a new dataframe to modify\n",
    "cdf = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop attributes\n",
    "Remaining attributes should satisfy following conditions.\n",
    "1. It tells the driver's state.\n",
    "2. It tells the environmental condition.\n",
    "3. It tells the motion of the car at and right before the accident.\n",
    "4. It is not skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['REPORT_NO', 'CDL_FLAG', 'CONDITION_CODE', 'EQUIP_PROB_CODE',\n",
       "       'FAULT_FLAG', 'INJ_SEVER_CODE', 'PERSON_ID', 'PERSON_TYPE',\n",
       "       'SAF_EQUIP_CODE', 'SEX_CODE', 'VEHICLE_ID', 'COLLISION_TYPE_CODE',\n",
       "       'C_M_ZONE_FLAG', 'JUNCTION_CODE', 'LANE_CODE', 'LIGHT_CODE',\n",
       "       'RD_COND_CODE', 'RD_DIV_CODE', 'SURF_COND_CODE', 'WEATHER_CODE',\n",
       "       'AREA_DAMAGED_CODE_MAIN', 'BODY_TYPE_CODE', 'DAMAGE_CODE',\n",
       "       'HIT_AND_RUN_FLAG', 'MOVEMENT_CODE', 'TIME', 'AGE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all column names as a list\n",
    "cdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'D': 29593})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if PERSON_TYPE is filled with a single value\n",
    "collections.Counter(cdf.PERSON_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First columns to drop\n",
    "del_cols = ['REPORT_NO', 'INJ_SEVER_CODE', 'PERSON_ID', 'PERSON_TYPE', 'VEHICLE_ID', 'TIME']\n",
    "# Drop columns\n",
    "ddf = cdf.drop(del_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reasons for neglection\n",
    "REPORT_NO: Report number is not of concern.  \n",
    "INJ_SEVER_CODE: This attribute will be used for analysis.  \n",
    "PERSON_ID: Individual ID is not of concern.  \n",
    "PERSON_TYPE: Every record already satisfies PERSON_TYPE == 'D'.  \n",
    "VEHICLE_ID: Vehicle ID is not of concern.  \n",
    "TIME: Since there is no attribute that can tell the traffic situation for each hour, day or month span, TIME attribute can only indicate environmental conditions which are indicated in other attributes. Hence, this attribute is unncessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDL_FLAG:\n",
      "\t[Max] N: 0.9596864123272395\n",
      "!!Data is greatly skewed.!!\n",
      "\n",
      "CONDITION_CODE:\n",
      "\t[Max] Apparently Normal: 0.9597539958774034\n",
      "!!Data is greatly skewed.!!\n",
      "\n",
      "EQUIP_PROB_CODE:\n",
      "\t[Max] No Misuse: 0.9966208224918055\n",
      "!!Data is greatly skewed.!!\n",
      "\n",
      "FAULT_FLAG:\n",
      "\t[Max] N: 0.58547629506978\n",
      "\n",
      "SAF_EQUIP_CODE:\n",
      "\t[Max] Shoulder/Lap Belt(s): 0.9799952691514885\n",
      "!!Data is greatly skewed.!!\n",
      "\n",
      "SEX_CODE:\n",
      "\t[Max] F: 0.5468185043760349\n",
      "\n",
      "COLLISION_TYPE_CODE:\n",
      "\t[Max] Same Direction Rear End: 0.34937316257222994\n",
      "\n",
      "C_M_ZONE_FLAG:\n",
      "\t[Max] N: 0.9844895752373872\n",
      "!!Data is greatly skewed.!!\n",
      "\n",
      "JUNCTION_CODE:\n",
      "\t[Max] Non Intersection: 0.5374243909032541\n",
      "\n",
      "LANE_CODE:\n",
      "\t[Max] Right Turn Lane: 0.6486669144730173\n",
      "\n",
      "LIGHT_CODE:\n",
      "\t[Max] Daylight: 0.6134896766127125\n",
      "\n",
      "RD_COND_CODE:\n",
      "\t[Max] No Defects: 0.9863143310918122\n",
      "!!Data is greatly skewed.!!\n",
      "\n",
      "RD_DIV_CODE:\n",
      "\t[Max] Two-way, Not Divided: 0.4170242962862839\n",
      "\n",
      "SURF_COND_CODE:\n",
      "\t[Max] Dry: 0.7480147332139357\n",
      "!!Data is greatly skewed.!!\n",
      "\n",
      "WEATHER_CODE:\n",
      "\t[Max] Clear: 0.7142567499070727\n",
      "!!Data is greatly skewed.!!\n",
      "\n",
      "AREA_DAMAGED_CODE_MAIN:\n",
      "\t[Max] Twelve o'clock: 0.388672996992532\n",
      "\n",
      "BODY_TYPE_CODE:\n",
      "\t[Max] Passenger Car: 0.6495792924002298\n",
      "\n",
      "DAMAGE_CODE:\n",
      "\t[Max] Disabling: 0.41945730409218396\n",
      "\n",
      "HIT_AND_RUN_FLAG:\n",
      "\t[Max] N: 0.9801980198019802\n",
      "!!Data is greatly skewed.!!\n",
      "\n",
      "MOVEMENT_CODE:\n",
      "\t[Max] Moving Constant Speed: 0.49200824519312\n",
      "\n",
      "AGE:\n",
      "\t[Max] 24.0: 0.030446389348832495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of columns to delete\n",
    "del_skew = []\n",
    "\n",
    "# Get column names as list\n",
    "col_list = ddf.columns\n",
    "\n",
    "# Identify columns with skewed data\n",
    "for col in col_list:\n",
    "    d = dict(collections.Counter(cdf['{}'.format(col)]))\n",
    "    # Key with max value\n",
    "    max_key = max(d, key=d.get)\n",
    "    # Max value\n",
    "    max_val = d[max_key]\n",
    "    # Percentage of max value\n",
    "    occ = max_val / len(ddf)\n",
    "    \n",
    "    print('{c}:\\n\\t[Max] {k}: {p}'.format(c=col, k=max_key, p=occ))\n",
    "    \n",
    "    # If the largest data of a column occupy more than 70%, assume the column skewed\n",
    "    if occ > 0.7:\n",
    "        # Add the column name in a list for to-be-deleted\n",
    "        del_skew.append(col)\n",
    "        print('!!Data is greatly skewed.!!')\n",
    "    \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns of skewed data\n",
    "ddf2 = ddf.drop(del_skew, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reasons for neglection\n",
    "Below attributes are dropped due to being highly skewed.  \n",
    "CDL_FLAG: 'N' 95%  \n",
    "CONDITION_CODE: 'Apparently Normal' 95%  \n",
    "EQUIP_PROB_CODE: 'No Misuse' 99%  \n",
    "SAF_EQUIP_CODE:'Shoulder/Lap Belts(s)' 97%  \n",
    "C_M_ZONE_FLAG: 'N' 98%  \n",
    "RD_COND_CODE: 'No Defects' 98%  \n",
    "SURF_COND_CODE: 'Dry' 74%  \n",
    "WEATHER_CODE: 'Clear' 71%  \n",
    "HIT_AND_RUN_FLAG: 'N' 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reasons for neglection\n",
    "REPORT_NO: Report number is not of concern.  \n",
    "CDL_FLAG: Data is skewed.  \n",
    "EQUIP_PROB_CODE: Safety equipment problem does not cause an accident.  \n",
    "FAULT_FLAG: Every record already satisfies FAULT_FLAG == 'Y'.  \n",
    "PERSON_ID: Individual ID is not of concern.  \n",
    "PERSON_TYPE: Every record already satisfies PERSON_TYPE == 'D'.  \n",
    "VEHICLE_ID: Vehicle ID is not of concern.  \n",
    "COLLISION_TYPE_CODE: How the cars collided is not of concern.  \n",
    "C_M_ZONE_FLAG: Data is skewed.  \n",
    "JUNCTION_CODE: Road structure is not of concern.  \n",
    "LANE_CODE: Road structure is not of concern.  \n",
    "RD_DIV_CODE: Road structure is not of concern.  \n",
    "SURF_COND_CODE: Surface condition may imply driver's state. However, it is hard to depict from this attribute.  \n",
    "AREA_DAMAGED_CODE_MAIN: Which part of the car is damaged is not of concern.  \n",
    "DAMAGE_CODE: Since casualty is expressed on INJ_SEVER_CODE, the amount of damage on the car is unnecessary.  \n",
    "HIT_AND_RUN_FLAG: Data is skewed. Also, hit-and-run happens after the collision. It seems unlikely it will represent the driver's state before collision.  \n",
    "TIME: Since there is no attribute that can tell the traffic situation for each hour, day or month span, TIME attribute can only indicate environmental conditions which are indicated in other attributes. Hence, this attribute is unncessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "drop_df = fault_df.drop(del_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all left column names\n",
    "drop_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change categorical values with only two options to numerical values\n",
    "d = {\n",
    "    'SEX_CODE': {'F': 0, 'M': 1},\n",
    "}\n",
    "\n",
    "rdf = drop_df.replace(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale AGE\n",
    "# Since AGE has values greater than any other column, its values should be scaled\n",
    "scaled_df = rdf.copy()\n",
    "scaled_df['AGE'] = (rdf['AGE'] - rdf['AGE'].min()) / (rdf['AGE'].max() - rdf['AGE'].min())\n",
    "# scaled_df['AGE'] = (rdf['AGE'] - rdf['AGE'].mean()) / rdf['AGE'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify all categorical data except INJ_SEVER_CODE\n",
    "dum_cols = [\n",
    "    'CONDITION_CODE', 'SAF_EQUIP_CODE','LIGHT_CODE',\n",
    "    'RD_COND_CODE', 'WEATHER_CODE', 'BODY_TYPE_CODE', 'MOVEMENT_CODE'\n",
    "]\n",
    "\n",
    "dum_df = pd.get_dummies(scaled_df, columns=dum_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate INJ_SEVER_CODE\n",
    "preprocessed_df = dum_df.drop('INJ_SEVER_CODE', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make all columns shown, find out the number of columns\n",
    "n = len(dum_df.columns)\n",
    "# Change display setting\n",
    "pd.options.display.max_columns = n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "n_clusters = 5\n",
    "kmodel = KMeans(n_clusters=n_clusters)\n",
    "kmodel.fit(preprocessed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted labels\n",
    "predicted_labels = kmodel.labels_\n",
    "drop_df['kmeans_labels'] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See if labels are skewed\n",
    "drop_df.groupby('kmeans_labels').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette average\n",
    "savg = silhouette_score(preprocessed_df, drop_df['kmeans_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette value of each data\n",
    "sval = silhouette_samples(preprocessed_df, drop_df['kmeans_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_silhouette(X_df, labels):\n",
    "    cluster_labels = sorted(np.unique(labels))\n",
    "    n_clusters = len(cluster_labels)\n",
    "    \n",
    "    plt.figure()\n",
    "\n",
    "    # axis setting\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim([-0.5, 1])\n",
    "    ax.set_ylim([0, X_df.shape[0] + (n_clusters + 1) * 10])\n",
    "\n",
    "    y_lower = 10\n",
    "    \n",
    "    silhouette_avg = silhouette_score(X_df, labels)\n",
    "    print(\"k : {}\".format(n_clusters))\n",
    "    print(\"silhouette_avg : {}\".format(silhouette_avg))\n",
    "    data_silhouette_values = silhouette_samples(X_df, labels)\n",
    "\n",
    "    for i in cluster_labels:\n",
    "        # 특정 클러스터의 silhouette 값만 추출\n",
    "        ith_cluster_silhouette_values = data_silhouette_values[labels == i]\n",
    "        \n",
    "        # 내림차순으로 정렬\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        # 해당 클러스터의 크기\n",
    "        size_cluster_i = len(ith_cluster_silhouette_values)\n",
    "       \n",
    "        # 클러스터의 silhouette을 표시할 y축 최고값 결정\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        # 색\n",
    "        color = cm.spectral(float(i) / n_clusters)\n",
    "        \n",
    "        # plot silhouette\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # y축에 클러스터 이름 표시\n",
    "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # 다음 클러스터의 silhouette을 표시할 최저점 조정\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax.set_title(\"The silhouette plot for k={}\".format(n_clusters))\n",
    "    ax.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # silhouette 평균 값을 나타내는 선\n",
    "    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    # y축 값 제거\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot silhouette for choosing k\n",
    "k_candidates = [2, 3, 4, 5, 6, 7]\n",
    "\n",
    "for i in k_candidates:\n",
    "    ith_model = KMeans(n_clusters=i)\n",
    "    labels = ith_model.fit_predict(preprocessed_df)\n",
    "    plot_silhouette(preprocessed_df, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X, y\n",
    "X, y = preprocessed_df, drop_df.kmeans_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class_weight = 'balanced'\n",
    "max_leaf_nodes = 5\n",
    "dt_model = DecisionTreeClassifier(class_weight=class_weight, max_leaf_nodes=max_leaf_nodes)\n",
    "# max_depth = 5\n",
    "# dt_model = DecisionTreeClassifier(class_weight=class_weight, max_depth=max_depth)\n",
    "dt_model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred_dt = dt_model.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get score\n",
    "dt_model.score(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export tree as .dot\n",
    "with open('test_tree.dot', 'w') as f:\n",
    "    export_graphviz(dt_model, f, feature_names=preprocessed_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open .dot and visualize\n",
    "with open('test_tree.dot', 'r') as f:\n",
    "    dot_graph = f.read()\n",
    "\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subclass k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataframe for subclass\n",
    "sub_df = scaled_df.copy()\n",
    "sub_df = sub_df[sub_df['MOVEMENT_CODE'] == 'Moving Constant Speed']\n",
    "sub_df = sub_df.drop('MOVEMENT_CODE', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify all categorical data except INJ_SEVER_CODE\n",
    "sub_dum_cols = [\n",
    "    'CONDITION_CODE', 'EQUIP_PROB_CODE', 'SAF_EQUIP_CODE','LIGHT_CODE',\n",
    "    'RD_COND_CODE', 'WEATHER_CODE', 'BODY_TYPE_CODE',\n",
    "]\n",
    "\n",
    "sub_dum_df = pd.get_dummies(sub_df, columns=sub_dum_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate INJ_SEVER_CODE\n",
    "sub_preprocessed_df = sub_dum_df.drop('INJ_SEVER_CODE', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "n_clusters = 5\n",
    "kmodel = KMeans(n_clusters=n_clusters)\n",
    "kmodel.fit(sub_preprocessed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted labels\n",
    "predicted_labels = kmodel.labels_\n",
    "sub_df['sub_kmeans_labels'] = predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subclass decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X, y\n",
    "X, y = sub_preprocessed_df, sub_df.sub_kmeans_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class_weight = 'balanced'\n",
    "max_leaf_nodes = 5\n",
    "dt_model = DecisionTreeClassifier(class_weight=class_weight, max_leaf_nodes=max_leaf_nodes)\n",
    "# max_depth = 5\n",
    "# dt_model = DecisionTreeClassifier(class_weight=class_weight, max_depth=max_depth)\n",
    "dt_model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred_dt = dt_model.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get score\n",
    "dt_model.score(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subclass graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export tree as .dot\n",
    "with open('test_tree_sub.dot', 'w') as f:\n",
    "    export_graphviz(dt_model, f, feature_names=sub_preprocessed_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open .dot and visualize\n",
    "with open('test_tree_sub.dot', 'r') as f:\n",
    "    dot_graph = f.read()\n",
    "\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
